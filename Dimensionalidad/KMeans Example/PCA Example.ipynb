{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Componentes Principales y Clustering\n",
    "\n",
    "## 1.- Importe las librerías correspondientes junto con el conjunto de datos\n",
    "* Necesitará el método `pd.read_excel` para poder ingerir los datos en formato `xlsx`.\n",
    "* El argumento `skiprows` le permite indicarle al lector que salte las primeras `n` líneas del archivo a leer\n",
    "* Recuerde definir una variable que sirva como semilla aleatoria!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "\n",
    "seed = 1123\n",
    "\n",
    "df = pd.read_excel('Residential-Building-Data-Set.xlsx', skiprows = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Data Wrangling & Feature Engineering\n",
    "1. Elimine las columnas `START QUARTER` y `COMPLETION QUARTER`, por ahora las ignoraremos para nuestro análisis.\n",
    "\n",
    "Nuestro primero objetivo será realizar una transformación/extracción de las componentes principales de la matriz de datos, el objetivo de esto es encontrar aquellas componentes principales que permiten explicar un cierto porcentaje de la variación total de los datos.\n",
    "\n",
    "2. Sabiendo que PCA en rigor solo debiese ser aplicado a variables numéricas de rango (recordar la diferencia entre variables ordinales y nominales), realice un split entrenamiento y test, apartando un conjunto de test correspondiente al 30% de la muestra. Considere que nuestra variable objetivo va a ser `COMPLETION YEAR`. Lo que haremos con el conjunto de train será pasarlo por la transformación PCA.\n",
    "> * _Observación:_ En mi caso particular, creo que prefiero dejar la dimensión de `START YEAR` fuera de la transformación pues la considero una variable más que todo ordinal.\n",
    "3. Antes de pasar el conjunto de datos, elimine todos los registros en los que `START YEAR` o `COMPLETION YEAR` es NaN.\n",
    "\n",
    "4. Escale la matriz de datos con la que se entrenará la transformación. Recuerde: Nunca debemos entrenar la transformación con todos los datos del dataset, de lo contrario, estaríamos pasando información del conjunto de test al modelo.\n",
    "> a. Instancie un objeto `StandarScaler` y entrenelo con el conjunto de entrenamiento\n",
    ">\n",
    "> b. Cree una nueva variable y asignele la transformación del conjunto de entrenamiento pasado por `StandarScaler`.\n",
    ">\n",
    "> c. Cree una nueva variable y asignele la transformación del conjunto de test pasado por `StandarScaler`.\n",
    "\n",
    "5. Transforme la matriz de atributos mediante PCA, para esto, realice los siguientes pasos:\n",
    "> a. Instancie un objeto `PCA` y entrenelo con la matriz de datos escalada __de entrenamiento__. Dentro de los argumentos del método, indique que requiere un número de componentes igual al $0.99$ de la variación total de los datos, además, indique `svd_solver = \"full\"`.\n",
    ">\n",
    "> b. Cree una nueva variable y asignele la transformación del conjunto de entrenamiento pasado por `PCA`.\n",
    ">\n",
    "> c. Cree una nueva variable y asignele la transformación del conjunto de test pasado por `PCA`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['START QUARTER', 'COMPLETION QUARTER'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['START YEAR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['START YEAR', 'COMPLETION YEAR'], inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pre, x_test_pre, y_train, y_test = train_test_split(df.drop('COMPLETION YEAR', axis = 1),\n",
    "                                                    df['COMPLETION YEAR'],\n",
    "                                                    test_size = .3,\n",
    "                                                    random_state = seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler().fit(x_train_pre.loc[:, 'V-1':])\n",
    "\n",
    "numeric_scaled_train = std_scaler.transform(x_train_pre.loc[:,'V-1':])\n",
    "\n",
    "numeric_scaled_test = std_scaler.transform(x_test_pre.loc[:,'V-1':])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transform = PCA(n_components = .95, svd_solver='full').fit(numeric_scaled_train)\n",
    "\n",
    "x_train = pd.DataFrame(pca_transform.transform(numeric_scaled_train))\n",
    "x_train['START YEAR'] = np.array(x_train_pre['START YEAR'])\n",
    "\n",
    "x_test = pd.DataFrame(pca_transform.transform(numeric_scaled_test))\n",
    "x_test['START YEAR'] = np.array(x_test_pre['START YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Estudio de las componentes encontradas\n",
    "\n",
    "1. Si decidió dejar la columna `START YEAR` fuera de la transformación, ahora agreguela como una nueva columna a las matrices de datos transformadas del punto anterior.\n",
    "\n",
    "2. Ralice un gráfico de barras donde se muestre:\n",
    "> a. En orden decreciente, la variación explicada por cada componente principal.\n",
    ">\n",
    "> b. La variación explicada acumulada a medida que se agregan componentes principales.\n",
    "\n",
    "__Nota:__ Es normal que la curva de variación explicada no parta de 0.\n",
    "\n",
    "Necesitará llamar a los argumentos `components_` y `explained_variance_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1- np.sum(pca_transform.explained_variance_ratio_[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = plt.subplots(figsize= (15,10))\n",
    "plt.bar(range(1, len(pca_transform.components_)+1),pca_transform.explained_variance_ratio_);\n",
    "sn.despine()\n",
    "plt.plot(range(1, len(pca_transform.components_)+1),pca_transform.explained_variance_ratio_, 'o-', color = 'tomato', label = 'Explained Variance');\n",
    "plt.plot(range(1, len(pca_transform.components_)+1),np.cumsum(pca_transform.explained_variance_ratio_), 'o-', label = 'Total Explained Variance')\n",
    "plt.axhline(.95)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.concat([x_train_pre.reset_index(drop = True), x_train.iloc[:,:-1].reset_index(drop = True)], axis = 1)\n",
    "df_pca.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.corr()[0].sort_values(ascending = False)[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = plt.subplots(figsize = (10,20))\n",
    "sn.barplot(y = df_pca.corr()[0].sort_values(ascending = False)[:150].index, x = np.abs(df_pca.corr()[0]).sort_values(ascending = False)[:150], orient = 'h')\n",
    "sn.despine()\n",
    "plt.axvline(0.8);\n",
    "#plt.xticks(size = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Modelamiento\n",
    "1. Realice una regresión lineal para poder predecir `COMPLETION YEAR`.\n",
    "2. Reporte la cantidad de varianza explicada por el modelo ($R^2$).\n",
    "3. Realice un dotplot entre `COMPLETION YEAR` y `START YEAR`, le hace sentido el valor que observó de varianza explicada?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "std2 = StandardScaler().fit(x_train)\n",
    "\n",
    "x_train_reg = std2.transform(x_train)\n",
    "x_test_reg = std2.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lin_reg = LinearRegression().fit(x_train_reg, y_train)\n",
    "lin_reg_preds = lin_reg.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, lin_reg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'col_name':x_train.columns, 'coefficient':lin_reg.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['START YEAR'], df['COMPLETION YEAR'], 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COMPLETION YEAR'].corr(df['START YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
